#!/usr/bin/env node

// ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
// Dockerç’°å¢ƒç”¨

import { Pool } from 'pg';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { dirname } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

export async function runMigrations() {
  console.log('ğŸ”„ Starting database migrations...');
  
  if (!process.env.DATABASE_URL) {
    console.warn('âš ï¸ DATABASE_URL is not set - skipping migrations');
    return;
  }

  try {
    const pool = new Pool({
      connectionString: process.env.DATABASE_URL,
      ssl: process.env.PG_SSL === 'require' ? { rejectUnauthorized: false } : false,
      max: 1,
    });

    const client = await pool.connect();
    
    // ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
    await client.query(`
      CREATE TABLE IF NOT EXISTS schema_migrations (
        id SERIAL PRIMARY KEY,
        filename VARCHAR(255) UNIQUE NOT NULL,
        executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `);

    // å®Ÿè¡Œæ¸ˆã¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å–å¾—
    const executedResult = await client.query('SELECT filename FROM schema_migrations');
    const executedFilenames = executedResult.rows.map(row => row.filename);

    // ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    const migrationsDir = path.join(__dirname, 'migrations');
    const migrationFiles = fs.readdirSync(migrationsDir)
      .filter(file => file.endsWith('.sql'))
      .sort();

    console.log(`ğŸ“ Found ${migrationFiles.length} migration files`);

    for (const filename of migrationFiles) {
      if (executedFilenames.includes(filename)) {
        console.log(`â­ï¸ Skipping already executed migration: ${filename}`);
        continue;
      }

      console.log(`ğŸ”„ Executing migration: ${filename}`);
      const migrationPath = path.join(migrationsDir, filename);
      const migrationSQL = fs.readFileSync(migrationPath, 'utf8');
      
      await client.query(migrationSQL);
      await client.query('INSERT INTO schema_migrations (filename) VALUES ($1)', [filename]);
      
      console.log(`âœ… Migration completed: ${filename}`);
    }

    await client.release();
    await pool.end();
    
    console.log('âœ… All migrations completed successfully');
  } catch (error) {
    console.error('âŒ Migration process failed:', error);
    throw error;
  }
}

// ç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆ
if (import.meta.url === `file://${process.argv[1]}`) {
  runMigrations().catch(console.error);
}
