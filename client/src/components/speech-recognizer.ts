import {
  AudioConfig,
  ResultReason,
  SpeechConfig,
  SpeechRecognizer,
} from 'microsoft-cognitiveservices-speech-sdk';

export interface ISpeechRecognizer {
  start(): void;
  stop(): void;
  sendToServer?: (text: string) => void;
}

export class AzureSpeechRecognizer implements ISpeechRecognizer {
  private recognizer: SpeechRecognizer | null = null;
  private accumulatedText: string = '';
  private lastSpokenTime: number = 0;
  private silenceCheckInterval: any = null;
  private textBuffer: string[] = [];

  // å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
  private readonly SILENCE_DETECTION_TIME = 1000; // ç„¡éŸ³æ¤œçŸ¥: 1ç§’
  private readonly AUTO_STOP_TIME = 10000; // è‡ªå‹•åœæ­¢: 10ç§’
  private readonly CHECK_INTERVAL = 200; // ãƒã‚§ãƒƒã‚¯é–“éš”: 200ms

  constructor(private azureKey: string, private azureRegion: string) {}

  async start() {
    console.log('ğŸ¤ AzureéŸ³å£°èªè­˜é–‹å§‹');
    console.log('ğŸ”‘ Azureè¨­å®šç¢ºèª:', { 
      key: this.azureKey ? `${this.azureKey.substring(0, 10)}...` : 'ãªã—',
      region: this.azureRegion 
    });

    // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’äº‹å‰ã«ç¢ºèªã—ã€éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ
    try {
      console.log('ğŸ™ï¸ ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’ç¢ºèªä¸­...');
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000
        } 
      });
      console.log('âœ… ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯æ¸ˆã¿');
      
      // éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’3ç§’é–“ç›£è¦–
      await this.testMicrophoneLevel(stream);
      
      stream.getTracks().forEach(track => track.stop()); // ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾
    } catch (error) {
      console.error('âŒ ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ã‚¢ã‚¯ã‚»ã‚¹æ‹’å¦:', error);
      throw new Error('ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ');
    }

    const speechConfig = SpeechConfig.fromSubscription(this.azureKey, this.azureRegion);
    speechConfig.speechRecognitionLanguage = 'ja-JP';
    
    // éŸ³å£°æ¤œå‡ºæ„Ÿåº¦ã‚’å¤§å¹…ã«æ”¹å–„
    speechConfig.setProperty('SpeechServiceConnection_InitialSilenceTimeoutMs', '15000');
    speechConfig.setProperty('SpeechServiceConnection_EndSilenceTimeoutMs', '5000');
    speechConfig.setProperty('SpeechServiceConnection_Mode', 'Conversation');
    speechConfig.setProperty('SpeechServiceConnection_RecoMode', 'CONVERSATION');
    speechConfig.setProperty('SpeechServiceConnection_EnableAudioLogging', 'true');
    
    // éŸ³å£°èªè­˜æ„Ÿåº¦ã®è©³ç´°è¨­å®š
    speechConfig.setProperty('SpeechServiceConnection_SilenceTimeoutMs', '2000');
    speechConfig.setProperty('SpeechServiceConnection_SingleShotTimeout', '30000');
    speechConfig.setProperty('SpeechServiceConnection_AutoDetectSourceLanguages', 'ja-JP');
    
    // éŸ³å£°å“è³ªã¨æ„Ÿåº¦ã®æœ€é©åŒ–
    speechConfig.setProperty('AudioConfig_AudioProcessingOptions', 'AEC_NoiseSuppression_AGC');
    speechConfig.setProperty('AudioConfig_DeviceNameForCapture', 'Default');
    speechConfig.setProperty('AudioConfig_PlaybackBufferLengthInMs', '100');
    speechConfig.setProperty('Speech_SegmentationSilenceTimeoutMs', '2000');
    
    console.log('ğŸšï¸ AzureéŸ³å£°è¨­å®šå®Œäº†:', {
      language: 'ja-JP',
      initialSilence: '8000ms',
      endSilence: '3000ms',
      mode: 'Interactive'
    });
    
    console.log('ğŸ¯ AudioConfigä½œæˆä¸­...');
    const audioConfig = AudioConfig.fromDefaultMicrophoneInput();
    this.recognizer = new SpeechRecognizer(speechConfig, audioConfig);
    console.log('ğŸ¯ SpeechRecognizerä½œæˆå®Œäº†');

    // ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆã®è¿½åŠ 
    this.recognizer.sessionStarted = (_, e) => {
      console.log('ğŸŸ¢ AzureéŸ³å£°èªè­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹:', e.sessionId);
    };

    this.recognizer.sessionStopped = (_, e) => {
      console.log('ğŸ”´ AzureéŸ³å£°èªè­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³åœæ­¢:', e.sessionId);
    };

    // éŸ³å£°æ¤œå‡ºã‚¤ãƒ™ãƒ³ãƒˆ
    this.recognizer.speechStartDetected = (_, e) => {
      console.log('ğŸµ éŸ³å£°æ¤œå‡ºé–‹å§‹ - è©±ã—å§‹ã‚ã¾ã—ãŸ');
      this.lastSpokenTime = Date.now();
    };

    this.recognizer.speechEndDetected = (_, e) => {
      console.log('ğŸ”‡ éŸ³å£°æ¤œå‡ºçµ‚äº† - è©±ã—çµ‚ã‚ã‚Šã¾ã—ãŸ');
    };

    this.recognizer.recognizing = (_, e) => {
      console.log('ğŸ¯ Azureèªè­˜ä¸­:', e.result.text, 'Reason:', this.getReasonText(e.result.reason));
      if (e.result.text.trim()) {
        this.accumulatedText = e.result.text;
        this.lastSpokenTime = Date.now();
      }
    };

    this.recognizer.recognized = (_, e) => {
      console.log('âœ… Azureèªè­˜å®Œäº†:', {
        text: e.result.text,
        reason: this.getReasonText(e.result.reason),
        duration: e.result.duration,
        offset: e.result.offset
      });
      
      if (e.result.reason === ResultReason.RecognizedSpeech && e.result.text.trim()) {
        this.textBuffer.push(e.result.text.trim());
        this.lastSpokenTime = Date.now();
        console.log('ğŸ“‹ ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ :', e.result.text.trim());
      } else if (e.result.reason === ResultReason.NoMatch) {
        console.log('ğŸ” éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ - ãƒã‚¤ã‚¯ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„');
      }
    };

    // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–
    this.recognizer.canceled = (_, e) => {
      console.error('âŒ Azureèªè­˜ã‚­ãƒ£ãƒ³ã‚»ãƒ«:', {
        reason: e.reason,
        errorCode: e.errorCode,
        errorDetails: e.errorDetails
      });
    };

    this.lastSpokenTime = Date.now();
    
    // éŸ³å£°æ¤œå‡ºã®è¿½åŠ è¨­å®š
    this.recognizer.properties.setProperty('SpeechServiceConnection_PhraseListTopic', 'ja-JP');
    this.recognizer.properties.setProperty('SpeechServiceConnection_WordLevelTimestamps', 'true');
    
    console.log('ğŸš€ Azureé€£ç¶šéŸ³å£°èªè­˜ã‚’é–‹å§‹ã—ã¾ã™...');
    this.recognizer.startContinuousRecognitionAsync(
      () => {
        console.log('âœ… Azureèªè­˜é–‹å§‹æˆåŠŸ - æ—¥æœ¬èªã§è©±ã—ã¦ãã ã•ã„ï¼ˆå¤§ãã‚ã®å£°ã§ï¼‰');
        console.log('ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ã€Œã“ã‚“ã«ã¡ã¯ã€ã€Œãƒ†ã‚¹ãƒˆã€ãªã©çŸ­ã„è¨€è‘‰ã‹ã‚‰è©¦ã—ã¦ãã ã•ã„');
      },
      (error) => {
        console.error('âŒ Azureèªè­˜é–‹å§‹ã‚¨ãƒ©ãƒ¼:', error);
      }
    );

    this.silenceCheckInterval = setInterval(() => {
      const now = Date.now();
      const silenceDuration = now - this.lastSpokenTime;

      // 1ç§’ã®ç„¡éŸ³æ¤œçŸ¥ã§ãƒãƒƒãƒ•ã‚¡å†…å®¹ã‚’é€ä¿¡
      if (silenceDuration > this.SILENCE_DETECTION_TIME && this.textBuffer.length > 0) {
        const combinedText = this.textBuffer.join(' ').trim();
        if (combinedText) {
          console.log('ğŸ“¤ Azureé€ä¿¡:', combinedText);
          this.sendToServer?.(combinedText);
        }
        this.textBuffer = [];
        this.accumulatedText = '';
      }

      // 10ç§’ã§è‡ªå‹•åœæ­¢
      if (silenceDuration > this.AUTO_STOP_TIME) {
        this.stop();
      }
    }, this.CHECK_INTERVAL);
  }

  stop() {
    if (this.recognizer) {
      this.recognizer.stopContinuousRecognitionAsync(() => {
        this.recognizer?.close();
        this.recognizer = null;
      });
    }
    clearInterval(this.silenceCheckInterval);
  }

  sendToServer?: (text: string) => void;

  private async testMicrophoneLevel(stream: MediaStream): Promise<void> {
    return new Promise((resolve) => {
      console.log('ğŸ”Š ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆ5ç§’é–“ï¼‰- è©±ã—ã¦ã¿ã¦ãã ã•ã„');
      
      const audioContext = new AudioContext();
      const analyser = audioContext.createAnalyser();
      const microphone = audioContext.createMediaStreamSource(stream);
      
      analyser.fftSize = 512;
      analyser.smoothingTimeConstant = 0.3;
      const bufferLength = analyser.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);
      
      microphone.connect(analyser);
      
      let maxLevel = 0;
      let avgLevel = 0;
      let sampleCount = 0;
      let speechDetected = false;
      const startTime = Date.now();
      const levels: number[] = [];
      
      const checkLevel = () => {
        analyser.getByteFrequencyData(dataArray);
        
        // éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—ï¼ˆã‚ˆã‚Šç²¾å¯†ã«ï¼‰
        let sum = 0;
        for (let i = 0; i < bufferLength; i++) {
          sum += dataArray[i];
        }
        const average = sum / bufferLength;
        levels.push(average);
        maxLevel = Math.max(maxLevel, average);
        avgLevel = levels.reduce((a, b) => a + b, 0) / levels.length;
        sampleCount++;
        
        // éŸ³å£°æ¤œå‡ºã®é–¾å€¤ã‚’ä¸‹ã’ã‚‹
        if (average > 15) {
          speechDetected = true;
        }
        
        // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¬ãƒ™ãƒ«è¡¨ç¤ºï¼ˆ1ç§’ã”ã¨ï¼‰
        if (sampleCount % 10 === 0) {
          console.log(`ğŸµ éŸ³å£°ãƒ¬ãƒ™ãƒ«: ${average.toFixed(1)} (æœ€å¤§: ${maxLevel.toFixed(1)}, å¹³å‡: ${avgLevel.toFixed(1)})`);
        }
        
        if (Date.now() - startTime < 5000) {
          setTimeout(checkLevel, 100);
        } else {
          console.log('ğŸ“Š ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆçµæœ:', {
            maxLevel: maxLevel.toFixed(2),
            avgLevel: avgLevel.toFixed(2),
            samples: sampleCount,
            speechDetected,
            recommendation: speechDetected ? 'âœ… éŸ³å£°æ¤œå‡ºè‰¯å¥½' : maxLevel > 10 ? 'âš ï¸ ã‚‚ã†å°‘ã—å¤§ããªå£°ã§è©±ã—ã¦ãã ã•ã„' : 'âŒ ãƒã‚¤ã‚¯éŸ³é‡ã‚’ä¸Šã’ã¦ãã ã•ã„'
          });
          
          audioContext.close();
          resolve();
        }
      };
      
      checkLevel();
    });
  }

  private getReasonText(reason: ResultReason): string {
    switch (reason) {
      case ResultReason.RecognizedSpeech:
        return 'RecognizedSpeech (éŸ³å£°èªè­˜æˆåŠŸ)';
      case ResultReason.NoMatch:
        return 'NoMatch (éŸ³å£°æ¤œå‡ºãªã—)';
      case ResultReason.Canceled:
        return 'Canceled (ã‚­ãƒ£ãƒ³ã‚»ãƒ«)';
      default:
        return `Unknown (${reason})`;
    }
  }
}

export class WebSpeechRecognizer implements ISpeechRecognizer {
  private recognition: SpeechRecognition;
  private accumulatedText: string = '';
  private lastSpokenTime: number = 0;
  private silenceCheckInterval: any = null;
  private textBuffer: string[] = [];
  public sendToServer?: (text: string) => void;

  // å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
  private readonly SILENCE_DETECTION_TIME = 1000; // ç„¡éŸ³æ¤œçŸ¥: 1ç§’
  private readonly AUTO_STOP_TIME = 10000; // è‡ªå‹•åœæ­¢: 10ç§’
  private readonly CHECK_INTERVAL = 200; // ãƒã‚§ãƒƒã‚¯é–“éš”: 200ms

  constructor() {
    console.log('ğŸŒ WebSpeechåˆæœŸåŒ–é–‹å§‹');
    const SpeechRecognition =
      (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;

    console.log('ğŸ” WebSpeech API ã‚µãƒãƒ¼ãƒˆç¢ºèª:', {
      webkitSpeechRecognition: !!(window as any).webkitSpeechRecognition,
      SpeechRecognition: !!(window as any).SpeechRecognition,
      userAgent: navigator.userAgent
    });

    if (!SpeechRecognition) {
      console.error('âŒ Web Speech API not supported');
      throw new Error('Web Speech API not supported');
    }

    this.recognition = new SpeechRecognition();
    console.log('âœ… WebSpeechèªè­˜ã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆå®Œäº†');
    this.recognition.lang = 'ja-JP';
    this.recognition.interimResults = true;
    this.recognition.continuous = true;

    this.recognition.onresult = (event: SpeechRecognitionEvent) => {
      console.log('ğŸ¯ WebSpeechçµæœå—ä¿¡:', event.results.length, 'ä»¶');
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        console.log(`ğŸ“ çµæœ${i}:`, result[0].transcript, 'isFinal:', result.isFinal);
        if (result.isFinal && result[0].transcript.trim()) {
          this.textBuffer.push(result[0].transcript.trim());
          this.lastSpokenTime = Date.now();
          console.log('ğŸ“‹ WebSpeechãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ :', result[0].transcript.trim());
        }
      }
    };

    this.recognition.onend = () => {
      console.log('ğŸ”„ WebSpeechèªè­˜çµ‚äº† - å†é–‹å§‹ã—ã¾ã™');
      if (this.silenceCheckInterval) {
        this.start();
      }
    };

    this.recognition.onerror = (event) => {
      console.error('âŒ WebSpeechèªè­˜ã‚¨ãƒ©ãƒ¼:', event.error);
    };

    this.recognition.onstart = () => {
      console.log('ğŸŸ¢ WebSpeechèªè­˜é–‹å§‹ã‚¤ãƒ™ãƒ³ãƒˆ');
    };

    this.recognition.onstop = () => {
      console.log('ğŸ”´ WebSpeechèªè­˜åœæ­¢ã‚¤ãƒ™ãƒ³ãƒˆ');
    };
  }

  start() {
    console.log('ğŸ¤ WebSpeechéŸ³å£°èªè­˜é–‹å§‹');

    // ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ã‚’æ˜ç¤ºçš„ã«ç¢ºèª
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(() => {
          console.log('âœ… ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯æ¸ˆã¿');
          this.recognition.start();
          this.lastSpokenTime = Date.now();
        })
        .catch((error) => {
          console.error('âŒ ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹æ‹’å¦:', error);
        });
    } else {
      console.log('âš ï¸ getUserMediaãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ - ç›´æ¥é–‹å§‹ã—ã¾ã™');
      this.recognition.start();
      this.lastSpokenTime = Date.now();
    }

    this.silenceCheckInterval = setInterval(() => {
      const now = Date.now();
      const silenceDuration = now - this.lastSpokenTime;

      // 1ç§’ã®ç„¡éŸ³æ¤œçŸ¥ã§ãƒãƒƒãƒ•ã‚¡å†…å®¹ã‚’é€ä¿¡
      if (silenceDuration > this.SILENCE_DETECTION_TIME && this.textBuffer.length > 0) {
        const combinedText = this.textBuffer.join(' ').trim();
        if (combinedText) {
          console.log('ğŸ“¤ WebSpeeché€ä¿¡:', combinedText);
          this.sendToServer?.(combinedText);
        }
        this.textBuffer = [];
        this.accumulatedText = '';
      }

      // 10ç§’ã§è‡ªå‹•åœæ­¢
      if (silenceDuration > this.AUTO_STOP_TIME) {
        this.stop();
      }
    }, this.CHECK_INTERVAL);
  }

  stop() {
    this.recognition.stop();
    clearInterval(this.silenceCheckInterval);
  }
}

export function createSpeechRecognizer(azureKey: string, azureRegion: string): ISpeechRecognizer {
  if (isIOS() && isSafari()) {
    return new WebSpeechRecognizer();
  } else {
    return new AzureSpeechRecognizer(azureKey, azureRegion);
  }
}



function isIOS(): boolean {
  return /iP(hone|od|ad)/.test(navigator.platform);
}

function isSafari(): boolean {
  return /^((?!chrome|android).)*safari/i.test(navigator.userAgent);
}