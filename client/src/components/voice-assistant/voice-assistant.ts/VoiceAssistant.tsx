
import React, { useState, useRef, useEffect } from 'react';
import { createSpeechRecognizer, ISpeechRecognizer } from '../speech-recognizer';

const VoiceAssistant = ({ onRecognized }: { onRecognized: (text: string) => void }) => {
  const [isRecording, setIsRecording] = useState(false);
  const recognizerRef = useRef<ISpeechRecognizer | null>(null);
  const speechBufferRef = useRef<string[]>([]);
  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const lastSpeechTimeRef = useRef<number>(0);
  
  const azureKey = process.env.REACT_APP_AZURE_SPEECH_KEY!;
  const azureRegion = process.env.REACT_APP_AZURE_SPEECH_REGION!;

  // Ë®≠ÂÆö
  const SILENCE_TIMEOUT = 3000; // 3Áßí„ÅÆÁÑ°Èü≥„ÅßÁµÇ‰∫Ü
  const MIN_SPEECH_LENGTH = 3; // ÊúÄÂ∞èÊñáÂ≠óÊï∞

  const isIOS = () => {
    return /iPad|iPhone|iPod/.test(navigator.userAgent) && !window.MSStream;
  };

  // „Éê„ÉÉ„Éï„Ç°Âá¶ÁêÜ
  const addToBuffer = (text: string) => {
    if (!text.trim()) return;
    
    console.log('üîÑ Èü≥Â£∞„Éê„ÉÉ„Éï„Ç°„Å´ËøΩÂä†:', text);
    speechBufferRef.current.push(text.trim());
    lastSpeechTimeRef.current = Date.now();
    
    // ÁÑ°Èü≥„Çø„Ç§„Éû„Éº„Çí„É™„Çª„ÉÉ„Éà
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
    }
    
    // Êñ∞„Åó„ÅÑÁÑ°Èü≥„Çø„Ç§„Éû„Éº„ÇíÈñãÂßã
    silenceTimeoutRef.current = setTimeout(() => {
      finalizeSpeech();
    }, SILENCE_TIMEOUT);
  };

  // Áô∫Ë©±ÁµÇ‰∫ÜÂá¶ÁêÜ
  const finalizeSpeech = () => {
    if (speechBufferRef.current.length === 0) return;
    
    const combinedText = speechBufferRef.current.join(' ').trim();
    console.log('‚úÖ Áô∫Ë©±Áµ±ÂêàÂÆå‰∫Ü:', combinedText);
    
    if (combinedText.length >= MIN_SPEECH_LENGTH) {
      onRecognized(combinedText);
      
      // ÁîªÂÉèÊ§úÁ¥¢„ÅÆ„Ç≠„Éº„ÉØ„Éº„Éâ„Åã„Å©„ÅÜ„Åã„ÉÅ„Çß„ÉÉ„ÇØ
      const imageSearchKeywords = ['„Éñ„É¨„Éº„Ç≠', '„Ç®„É≥„Ç∏„É≥', 'ÂÜ∑Âç¥', '„Éõ„Ç§„Éº„É´', 'ËªäËº™', 'ÈÉ®ÂìÅ', 'Ë®≠ÂÇô', 'Ê©üÊ¢∞', '‰øùÂÆà', 'ÁÇπÊ§ú'];
      const hasImageKeyword = imageSearchKeywords.some(keyword => 
        combinedText.includes(keyword)
      );
      
      if (hasImageKeyword) {
        console.log('üîç Èü≥Â£∞„Åã„ÇâÁîªÂÉèÊ§úÁ¥¢„Ç≠„Éº„ÉØ„Éº„Éâ„ÇíÊ§úÂá∫:', combinedText);
        // ÁîªÂÉèÊ§úÁ¥¢„ÇíÂÆüË°å
        window.dispatchEvent(new CustomEvent('voice-search-request', {
          detail: { query: combinedText }
        }));
      }
    } else {
      console.log('‚ö†Ô∏è Áô∫Ë©±„ÅåÁü≠„Åô„Åé„Åæ„Åô:', combinedText);
    }
    
    // „Éê„ÉÉ„Éï„Ç°„Çí„ÇØ„É™„Ç¢
    speechBufferRef.current = [];
    
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current);
      silenceTimeoutRef.current = null;
    }
  };

  // Ë™çË≠òÈñãÂßã
  const startRecognition = async () => {
    if (isRecording) return;
    
    try {
      setIsRecording(true);
      speechBufferRef.current = [];
      lastSpeechTimeRef.current = Date.now();
      
      console.log('üé§ Èü≥Â£∞Ë™çË≠òÈñãÂßã -', isIOS() ? 'Web Speech API' : 'Azure Speech SDK');
      
      // speech-recognizer.ts„ÅÆ„Éï„Ç°„ÇØ„Éà„É™Èñ¢Êï∞„Çí‰ΩøÁî®
      recognizerRef.current = createSpeechRecognizer(azureKey, azureRegion);
      
      // Ë™çË≠òÁµêÊûú„ÇíÂèó‰ø°„Åô„ÇãÂá¶ÁêÜ„ÇíË®≠ÂÆö
      recognizerRef.current.sendToServer = (text: string) => {
        console.log('üîä Èü≥Â£∞Ë™çË≠òÁµêÊûúÂèó‰ø°:', text);
        addToBuffer(text);
      };
      
      // Ë™çË≠òÈñãÂßã
      await recognizerRef.current.start();
      
    } catch (error) {
      console.error('‚ùå Èü≥Â£∞Ë™çË≠òÈñãÂßã„Ç®„É©„Éº:', error);
      setIsRecording(false);
      alert('Èü≥Â£∞Ë™çË≠ò„ÅÆÈñãÂßã„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: ' + (error as Error).message);
    }
  };

  // Ë™çË≠òÂÅúÊ≠¢
  const stopRecognition = () => {
    if (!isRecording) return;
    
    console.log('üõë Èü≥Â£∞Ë™çË≠òÂÅúÊ≠¢');
    
    if (recognizerRef.current) {
      recognizerRef.current.stop();
      recognizerRef.current = null;
    }
    
    // ÊÆã„Å£„Å¶„ÅÑ„Çã„Éê„ÉÉ„Éï„Ç°„ÇíÂá¶ÁêÜ
    finalizeSpeech();
    
    setIsRecording(false);
  };

  // „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
  useEffect(() => {
    return () => {
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current);
      }
      if (recognizerRef.current) {
        recognizerRef.current.stop();
      }
    };
  }, []);

  // Ëá™ÂãïÂÅúÊ≠¢Áõ£Ë¶ñÔºà10ÁßíÂæå„Å´Ëá™ÂãïÂÅúÊ≠¢Ôºâ
  useEffect(() => {
    if (!isRecording) return;
    
    const autoStopTimeout = setTimeout(() => {
      console.log('‚è∞ Ëá™ÂãïÂÅúÊ≠¢Ôºà10ÁßíÁµåÈÅéÔºâ');
      stopRecognition();
    }, 10000);
    
    return () => clearTimeout(autoStopTimeout);
  }, [isRecording]);

  return (
    <div className="voice-assistant">
      <button 
        onClick={isRecording ? stopRecognition : startRecognition}
        className={`voice-button ${isRecording ? 'recording' : ''}`}
        disabled={!azureKey && !isIOS()}
      >
        {isRecording ? (
          <span>
            üî¥ Èå≤Èü≥‰∏≠... 
            <small style={{ display: 'block', fontSize: '0.8em' }}>
              ({speechBufferRef.current.length}‰ª∂Ë™çË≠òÊ∏à„Åø)
            </small>
          </span>
        ) : (
          'üéôÔ∏è „Éû„Ç§„ÇØÈñãÂßã'
        )}
      </button>
      
      {isRecording && (
        <div className="recording-status">
          <div className="pulse-animation"></div>
          <span>Áô∫Ë©±„ÇíËÅû„ÅÑ„Å¶„ÅÑ„Åæ„Åô...</span>
          {speechBufferRef.current.length > 0 && (
            <div className="buffer-preview">
              ÊúÄÊñ∞: "{speechBufferRef.current[speechBufferRef.current.length - 1]}"
            </div>
          )}
        </div>
      )}
      
      <style jsx>{`
        .voice-assistant {
          display: flex;
          flex-direction: column;
          align-items: center;
          gap: 10px;
        }
        
        .voice-button {
          padding: 12px 24px;
          font-size: 16px;
          border: 2px solid #4CAF50;
          background: white;
          border-radius: 25px;
          cursor: pointer;
          transition: all 0.3s ease;
        }
        
        .voice-button:hover {
          background: #f0f8f0;
        }
        
        .voice-button.recording {
          background: #ffebee;
          border-color: #f44336;
          animation: pulse 2s infinite;
        }
        
        .recording-status {
          text-align: center;
          color: #666;
          font-size: 14px;
        }
        
        .buffer-preview {
          margin-top: 5px;
          font-style: italic;
          color: #888;
          max-width: 300px;
          overflow: hidden;
          text-overflow: ellipsis;
          white-space: nowrap;
        }
        
        .pulse-animation {
          display: inline-block;
          width: 8px;
          height: 8px;
          background: #f44336;
          border-radius: 50%;
          margin-right: 8px;
          animation: pulse 1s infinite;
        }
        
        @keyframes pulse {
          0% { transform: scale(1); opacity: 1; }
          50% { transform: scale(1.2); opacity: 0.7; }
          100% { transform: scale(1); opacity: 1; }
        }
      `}</style>
    </div>
  );
};

export default VoiceAssistant;
